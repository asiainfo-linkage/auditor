#Pipeline
#pipeline name
oci.auditor.com.ailk.oci.auditor.pipeline.config.service.name=unknown
oci.auditor.com.ailk.oci.auditor.pipeline.config.queue.full.policy=shutdown
oci.auditor.com.ailk.oci.auditor.pipeline.config.queue.size=1024

#pipeline out processor
#eventPersistenceProcessor=  


#EventUploadProcessor,config to server url/server
oci.auditor.com.ailk.oci.auditor.pipeline.config.processor.upload.server.url=http://10.1.253.177:8080/server

#DuplicateFilter
com.ailk.oci.auditor.pipeline.processor.in.filter.duplicate.debug = true
com.ailk.oci.auditor.pipeline.processor.in.filter.duplicate.rule = package com.ailk.oci.auditor.plugin.audit.pipeline.processor.in.filter.field
import com.ailk.oci.auditor.protocol.event.pipeline.avro.*;
import com.ailk.oci.auditor.pipeline.processor.in.filter.DuplicateFilter.CandidateElement;
global com.ailk.oci.auditor.pipeline.processor.in.filter.DuplicateFilter filter
rule "Hdfs User filter"
 dialect "mvel"
 when
 c: CandidateElement(element#Event.event instanceof HdfsEvent,user:element#Event.user,localTime:element#Event.localTime,operation:element#Event.operation,src:element#Event.event#HdfsEvent.src)
 then
 filter.duplicateCheck(c,localTime,4000,[user,operation,src])
end

com.ailk.oci.auditor.pipeline.processor.in.filter.duplicate.window.size = 1024


#hiveExecHook,config file
oci.auditor.com.ailk.oci.auditor.pipeline.hive.exec.config=
